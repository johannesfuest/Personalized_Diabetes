{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import plotly.express as px\n",
    "import sys\n",
    "sys.path.append('../personalized-diabetes')\n",
    "from sigopt_functions import gMSE, Pen, gSE\n",
    "import tensorflow as tf\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '../personalized-diabetes/preds'\n",
    "REGEX = 'base_(\\d)_(train|test)_M(\\d+)_D(\\d+).csv' \n",
    "M_global = [      10,20,50,100,200,400,800,1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dfs(baselines):\n",
    "    dfs = []\n",
    "    for B, d_range in baselines.items():\n",
    "        for M in M_global:\n",
    "            for mode in ['train', 'test']:\n",
    "                for D in d_range:\n",
    "                    if D == 0:\n",
    "                        df = pd.read_csv(os.path.join(DIR, f'base_{B}_{mode}_M{M}.csv'))\n",
    "                    else:\n",
    "                        df = pd.read_csv(os.path.join(DIR, f'base_{B}_{mode}_M{M}_D{D}.csv'))\n",
    "                    df['M'] = M\n",
    "                    df['D'] = D\n",
    "                    df['B'] = B\n",
    "                    df['split'] = mode\n",
    "                    dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    df.rename(columns={'0':'y_hat'}, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_granular_mses(df, baselines_dict):\n",
    "    res = []\n",
    "    for B, d_range in baselines_dict.items():\n",
    "        for M in M_global:\n",
    "            #train_mse = np.mean(np.square(df[df.split=='train'].y - df[df.split=='train'].y_hat))\n",
    "            #test_mse = np.mean(np.square(df[df.split=='test'].y - df[df.split=='test'].y_hat))\n",
    "\n",
    "            for D in d_range:\n",
    "                df_train = df[(df.split=='train')&(df.D==D)&(df.M==M)&(df.B==B)]\n",
    "                df_test = df[(df.split=='test')&(df.D==D)&(df.M==M)&(df.B==B)]\n",
    "                train_mse_d = np.mean(np.square(df_train.y - df_train.y_hat))\n",
    "                test_mse_d = np.mean(np.square(df_test.y - df_test.y_hat))\n",
    "                train_gmse_d = gMSE(df_train.y, df_train.y_hat)\n",
    "                test_gmse_d = gMSE(df_test.y, df_test.y_hat)\n",
    "                res.append({'D': D, 'M':M, 'B': B, 'split': 'train', 'mse': train_mse_d, 'gmse': train_gmse_d, 'weights': df_train.shape[0]})\n",
    "                res.append({'D': D, 'M':M, 'B': B, 'split': 'test',  'mse': test_mse_d,  'gmse':  test_gmse_d, 'weights': df_test.shape[0]})\n",
    "    res_df = pd.DataFrame(res)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproduce_agg_stats(df_all, baselines_dict, verbose=True):\n",
    "    res = []\n",
    "    for B in baselines_dict.keys():\n",
    "        for M in M_global:\n",
    "\n",
    "            df = df_all[(df_all.M==M)&(df_all.B==B) ]\n",
    "            try: \n",
    "                train_weighted = np.average(df[df.split=='train'].mse, weights =df[df.split=='train'].weights)\n",
    "\n",
    "                train_weighted_gmse = np.average(df[df.split=='train'].gmse, weights =df[df.split=='train'].weights)\n",
    "                res.append({'M': M, 'B': B, 'Weighted':True, 'split':'train', 'mse': train_weighted, 'gmse': train_weighted_gmse})\n",
    "            except ZeroDivisionError:\n",
    "                print(f'Zero division error at train, B{B}, M{M}')\n",
    "\n",
    "            try:\n",
    "                test_weighted = np.average(df[df.split=='test'].mse, weights = df[df.split=='test'].weights)\n",
    "                test_gmse_weighted = np.average(df[df.split=='test'].gmse, weights = df[df.split=='test'].weights)\n",
    "                res.append({'M': M, 'B': B, 'Weighted':True, 'split':'test', 'mse': test_weighted, 'gmse': test_gmse_weighted})\n",
    "            except ZeroDivisionError: \n",
    "                print(f'Zero division error at test, B{B}, M{M}')\n",
    "                \n",
    "            train_unweighted = np.average(df[df.split=='train'].mse)\n",
    "            train_gmse_unweighted = np.average(df[df.split=='train'].gmse)\n",
    "\n",
    "            res.append({'M': M, 'B': B, 'Weighted':False, 'split':'train', 'mse': train_unweighted, 'gmse': train_gmse_unweighted})\n",
    "            test_unweighted = np.average(df[df.split=='test'].mse)\n",
    "            test_gmse_unweighted = np.average(df[df.split=='test'].gmse)\n",
    "\n",
    "            res.append({'M': M, 'B': B, 'Weighted':False, 'split':'test', 'mse': test_unweighted, 'gmse': test_gmse_unweighted})\n",
    "            \n",
    "\n",
    "    return pd.DataFrame(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excl = [1,9,10,12,16,18,19,21,22,23,24,25,26,27,29,30]\n",
    "#list(set(range(1,31)) - set(excl))\n",
    "baselines_dict = {\n",
    "    1: [0],\n",
    "    #11: [0],\n",
    "    #21: [0],\n",
    "    3: range(1,31),\n",
    "    #5: range(1,31),\n",
    "    6: range(1,31),\n",
    "    7: [0],\n",
    "   # 101: [0],\n",
    "   # 106: range(1,31),\n",
    "   # 116: range(1,31),\n",
    "}\n",
    "\n",
    "baselines = load_dfs(baselines_dict)\n",
    "baselines[baselines.B==7]\n",
    "baselines.loc[baselines.B==7, 'D'] = baselines.loc[baselines.B==7, 'DeidentID'].astype(int)\n",
    "baselines.drop(columns=['DeidentID'], inplace=True)\n",
    "baselines_dict = {\n",
    "    1: [0],\n",
    "    #11: [0],\n",
    "    #21: [0],\n",
    "    3: range(1,31),\n",
    "    #5: range(1,31),\n",
    "    6: range(1,31),\n",
    "    7: range(1,31),\n",
    "   # 101: [0],\n",
    "   # 106: range(1,31),\n",
    "   # 116: range(1,31),\n",
    "}\n",
    "res_df = calc_granular_mses(baselines, baselines_dict)\n",
    "res_df.gmse = res_df.gmse.apply(lambda x: x.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res_df.to_pickle('res_df.pickle')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baselines_dict = {\n",
    "    1: [0],\n",
    "    11: [0],\n",
    "    21: [0],\n",
    "    3: range(1,31),\n",
    "    5: range(1,31),\n",
    "    6: range(1,31),\n",
    "    101: [0],\n",
    "    106: range(1,31),\n",
    "    116: range(1,31),\n",
    "}\n",
    "\n",
    "res_df = pd.read_pickle('res_df.pickle')\n",
    "_ = reproduce_agg_stats(res_df, baselines_dict, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res_df.D = res_df.D.astype(str)\n",
    "px.scatter(res_df, x='M', color='D', y='mse', facet_col='split', facet_row='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_to_exclude = [1,9,10,12,16,18,19,21,22,23,24,25,26,27,29,30]\n",
    "#patients_to_exclude = []\n",
    "agg_stats = reproduce_agg_stats(res_df[(~res_df.D.isin(patients_to_exclude))], baselines_dict, verbose=False)\n",
    "\n",
    "px.line(agg_stats[agg_stats.split=='test'], x='M', y='gmse', color='B', facet_col='Weighted', markers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = agg_stats.loc[(agg_stats.Weighted) & (agg_stats.split=='test'), ['M', 'B', 'gmse']].pivot(index=['B'], columns=['M'], values=['gmse']).round(2).to_string().split('\\n')\n",
    "vals = ['&'.join(ele.split()) for ele in x]\n",
    "print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots for file\n",
    "patients_to_exclude = [1,9,10,12,16,18,19,21,22,23,24,25,26,27,29,30]\n",
    "#patients_to_exclude = []\n",
    "agg_stats = reproduce_agg_stats(res_df[(~res_df.D.isin(patients_to_exclude)) ], baselines_dict, verbose=False)\n",
    "\n",
    "fig = px.line(agg_stats[(agg_stats.split=='test')&(agg_stats.Weighted)], x='M', y='gmse', color='B', markers=True, labels={'M': 'Missingness Modulo', 'gmse': 'gMSE', 'B': 'Baseline'},  width=1500, height=1000)\n",
    "fig.update_layout(font=dict(size=20))\n",
    "\n",
    "fig.write_image('Model_Performances.png')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines scatter colorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tensor = tf.constant(baselines.y, dtype=tf.float32)\n",
    "Y_hat_tensor = tf.constant(baselines.y_hat, dtype=tf.float32)\n",
    "\n",
    "baselines = baselines.assign(pen=Pen(g = Y_tensor, g_hat = Y_hat_tensor, ), gSE = gSE(g = Y_tensor, g_hat = Y_hat_tensor, )[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(baselines[(baselines.M==1000)&(baselines.split=='test')], x='y', y='y_hat', color='pen', height=800, width=1200, color_continuous_scale='RdYlGn_r', opacity=0.05, facet_col='B', facet_col_wrap=2,labels={'M': 'Missingness Modulo', 'gmse': 'gMSE', 'B': 'Baseline'})\n",
    "fig.update_traces(marker=dict(size=2))\n",
    "fig.update_layout(\n",
    "    plot_bgcolor='white',\n",
    "    \n",
    ")\n",
    "fig.update_xaxes(showline=True, linewidth=1, linecolor='black', mirror=True, showgrid=True, gridwidth=1, gridcolor='LightGrey')\n",
    "fig.update_yaxes(showline=True, linewidth=1, linecolor='black', mirror=True, showgrid=True, gridwidth=1, gridcolor='LightGrey')\n",
    "\n",
    "#fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightPink')\n",
    "#fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightPink')\n",
    "fig.write_image('scatter_pen.png')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(baselines[(baselines.M==1000)&(baselines.split=='test')], x='y', y='y_hat', color='gSE', height=1000, width=1500, color_continuous_scale='RdYlGn_r', range_color=[0,10000], opacity=0.04, facet_col='B', facet_col_wrap=2, labels={'M': 'Missingness Modulo', 'gmse': 'gMSE', 'B': 'Baseline'})\n",
    "fig.update_traces(marker=dict(size=2))\n",
    "fig.update_layout(\n",
    "    plot_bgcolor='white',\n",
    "    \n",
    ")\n",
    "fig.update_xaxes(showline=True, linewidth=1, linecolor='black', mirror=True, showgrid=True, gridwidth=1, gridcolor='LightGrey')\n",
    "fig.update_yaxes(showline=True, linewidth=1, linecolor='black', mirror=True, showgrid=True, gridwidth=1, gridcolor='LightGrey')\n",
    "fig.update_layout(font=dict(size=20))\n",
    "#fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightPink')\n",
    "#fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightPink')\n",
    "fig.write_image('scatter_gSE.png')\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export for Leander"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baselines_dict_leander = {\n",
    "    1: [0],\n",
    "    #11: [0],\n",
    "    #21: [0],\n",
    "   # 101: [0],\n",
    "   # 106: range(1,31),\n",
    "   # 116: range(1,31),\n",
    "}\n",
    "[      10,20,50,100,200, 400, 800,1000]\n",
    "baselines_leander = load_dfs(baselines_dict_leander)\n",
    "baselines_leander.to_csv('base_1_leander.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines[baselines.M==10].groupby('split').run.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs230",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
